{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46408184",
   "metadata": {},
   "source": [
    "# Tarea 2 — Inteligencia Artificial (UDP)\n",
    "\n",
    "**Instrucciones clave (resumen de la pauta):**  \n",
    "- **Clustering**: K-Means, K-Means++ y MeanShift, **al menos 4 configs por técnica**, entrenar con **80%** (sin Y), evaluar con métrica (p.ej., Silhouette) y **elegir top-3**; aplicar al **20%**, asignar etiqueta por **clase dominante del cluster** y discutir razonabilidad.  \n",
    "- **Supervisado**: Entrenar en **paralelo** múltiples instancias (≥3 por técnica) de **Regresión Logística** y **SVM**, **variando hiperparámetros** definidos en un **archivo de configuración externo**; entrenar con **80%** y **cada 5 épocas eliminar la peor**; para las **mejores 2 configs**, reportar métricas en **20%**.  \n",
    "\n",
    "> **Nota académica:** Esta notebook contiene **código y estructura**. Debes **redactar tu propio análisis** en las celdas marcadas como *[Completar análisis]*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a528177",
   "metadata": {},
   "source": [
    "## 0) Setup del entorno (local)\n",
    "\n",
    "1. Asegúrate de tener un entorno de Python 3.10+ (puede ser `conda` o `venv`).  \n",
    "2. Instala dependencias en tu máquina:\n",
    "```bash\n",
    "pip install -r ../requirements.txt\n",
    "```\n",
    "Si usas VS Code, puedes abrir esta carpeta y ejecutar esta notebook con la extensión de Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)              # Debe mostrar /usr/bin/python\n",
    "import sklearn, numpy, scipy\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"numpy:\", numpy.__version__, \"scipy:\", scipy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29435746",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m silhouette_score\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_config, load_dataset, build_preprocessor, split_xy, make_splits\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_clustering\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Imports principales\n",
    "import os, json, yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from src.utils import read_config, load_dataset, build_preprocessor, split_xy, make_splits\n",
    "from src.clustering import run_clustering\n",
    "from src.supervised import train_with_elimination\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46f15f",
   "metadata": {},
   "source": [
    "## 1) Cargar configuración y dataset\n",
    "\n",
    "- Edita `../config/config.yaml` para ajustar:\n",
    "  - `dataset_path`: ruta a tu CSV (por ejemplo, `data/ai4i_2020.csv` descargado de Kaggle).\n",
    "  - `target_column`: nombre exacto de la columna Y (p.ej., `Failure Type`).\n",
    "  - `drop_columns`, `categorical_columns`: ajusta de acuerdo a tu archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_PATH = str(Path('../config/config.yaml'))\n",
    "cfg = read_config(CFG_PATH)\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae305aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CSV y chequear columnas\n",
    "df, target_col, num_cols, cat_cols = load_dataset(cfg)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "print(\"Objetivo (Y):\", target_col)\n",
    "print(\"Categóricas detectadas:\", cat_cols)\n",
    "print(\"Numéricas:\", num_cols)\n",
    "\n",
    "# Resumen de clases (para verificar multiclase)\n",
    "print(\"\\nDistribución de la etiqueta Y:\")\n",
    "print(df[target_col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a9248",
   "metadata": {},
   "source": [
    "## 2) Separar train/test (80/20) y preparar *preprocessor*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c645cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_xy(df, target_col)\n",
    "X_train, X_test, y_train, y_test = make_splits(X, y, test_size=cfg['test_size'], random_state=cfg['random_state'])\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# El preprocesador se ajusta solo con train (para evitar leakage)\n",
    "pre = build_preprocessor(num_cols, cat_cols)\n",
    "Xtr = pre.fit_transform(X_train)\n",
    "Xte = pre.transform(X_test)\n",
    "Xtr.shape, Xte.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64bbcc",
   "metadata": {},
   "source": [
    "## 3) Clustering: K-Means / K-Means++ / MeanShift\n",
    "\n",
    "- Entrenamos **solo con X_train** (sin Y), probando ≥4 configuraciones por técnica.\n",
    "- Evaluamos con la métrica elegida (p.ej. *Silhouette*). Elegimos el **Top-3** y medimos la **asignación por etiqueta dominante** en el 20% de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0999297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results, top3, pre_used = run_clustering(cfg, X_train, y_train, X_test, y_test, num_cols, cat_cols)\n",
    "print(\"== Resultados (ordenado por métrica en train) ==\")\n",
    "display(df_results.head(12))\n",
    "print(\"\\n== TOP-3 por métrica en train ==\")\n",
    "display(top3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad4f52",
   "metadata": {},
   "source": [
    "### [Completar análisis] — *Clustering*\n",
    "- Comenta brevemente las configuraciones que obtuvieron mejor puntaje (métrica en train).\n",
    "- Discute si la asignación de **etiqueta dominante por cluster** al 20% de test parece razonable para imputar etiquetas faltantes.\n",
    "- Agrega gráficos si lo estimas necesario (p.ej., distribución de tamaños de cluster). **No uses IA generativa para redactar este análisis.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06494c",
   "metadata": {},
   "source": [
    "## 4) Modelos Supervisados (Logistic / SVM) con eliminación periódica\n",
    "\n",
    "- Entrenamos **en paralelo** múltiples configuraciones (definidas en `config.yaml`), **solo con train**.\n",
    "- Cada **5 épocas**, eliminamos la **peor** configuración (según métrica en *train*).\n",
    "- Reportamos métricas en **test** para las **dos mejores** configuraciones finales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ffedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional) Puedes ajustar n_jobs según tu CPU; -1 usa todos los núcleos\n",
    "train_history, test_summary, survivors = train_with_elimination(cfg, Xtr, y_train, Xte, y_test, class_names=None, n_jobs=-1)\n",
    "\n",
    "print(\"== Historial de evaluación (train) ==\")\n",
    "display(train_history)\n",
    "\n",
    "print(\"\\n== Métricas en test para las 2 mejores configuraciones ==\")\n",
    "display(test_summary[[\"name\",\"algo\",\"test_accuracy\",\"test_f1_macro\"]])\n",
    "\n",
    "# Guardar resultados\n",
    "Path(\"outputs\").mkdir(exist_ok=True)\n",
    "train_history.to_csv(\"outputs/train_history.csv\", index=False)\n",
    "test_summary.to_csv(\"outputs/test_summary.csv\", index=False)\n",
    "print(\"Archivos guardados en outputs/: train_history.csv y test_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9f4e7",
   "metadata": {},
   "source": [
    "### [Completar análisis] — *Supervisado*\n",
    "- Explica cómo afectaron los **hiperparámetros** al rendimiento (por ejemplo, `alpha`, `learning_rate`, `loss`).\n",
    "- Compara **Regresión Logística** vs **SVM** en las métricas de test (accuracy, F1 macro).\n",
    "- Comenta brevemente el efecto de la **eliminación cada 5 épocas** sobre la convergencia de las configuraciones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
